{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DQN vs. PPO on Atari Pong\n",
    "\n",
    "This notebook loads the training data generated by `scripts/train.py` and produces learning curves to compare the performance of the different agents, consistent with the figures in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Experiment Data\n",
    "\n",
    "We'll scan the `data/` directory to find all the training runs, load their `log.csv` files, and combine them into a single DataFrame. We extract the agent name and seed from the directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "SEEDS = [42, 84, 126]\n",
    "AGENTS = ['dqn_vanilla', 'dqn_enhanced', 'ppo']\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for agent in AGENTS:\n",
    "    for seed in SEEDS:\n",
    "        # Find the directory that matches the agent and seed\n",
    "        run_dirs = [d for d in os.listdir(DATA_DIR) if d.startswith(f\"{agent}__{seed}\")]\n",
    "        if not run_dirs:\n",
    "            print(f\"Warning: No data found for {agent} with seed {seed}\")\n",
    "            continue\n",
    "        \n",
    "        run_dir = run_dirs[0] # Assume only one run per agent/seed\n",
    "        log_path = os.path.join(DATA_DIR, run_dir, 'log.csv')\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(log_path)\n",
    "            df['agent'] = agent\n",
    "            df['seed'] = seed\n",
    "            all_data.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: log.csv not found in {run_dir}\")\n",
    "\n",
    "if all_data:\n",
    "    results_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Total rows: {len(results_df)}\")\n",
    "    results_df.head()\n",
    "else:\n",
    "    print(\"No data was loaded. Please run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot Learning Curves\n",
    "\n",
    "Now we'll use Seaborn's `lineplot` to visualize the mean evaluation return over training frames. The shaded area represents the 95% confidence interval across the different seeds, giving us a measure of training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(df, title, x='step', y='eval/mean_return', hue='agent'):\n",
    "    \"\"\"Helper function to plot learning curves with confidence intervals.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Seaborn automatically calculates mean and 95% CI\n",
    "    sns.lineplot(data=df, x=x, y=y, hue=hue, errorbar=('ci', 95))\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Environment Frames', fontsize=12)\n",
    "    plt.ylabel('Mean Episode Return', fontsize=12)\n",
    "    plt.legend(title='Agent')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Filter out rows without evaluation data\n",
    "eval_df = results_df.dropna(subset=['eval/mean_return'])\n",
    "eval_df['step_in_millions'] = eval_df['step'] / 1_000_000\n",
    "\n",
    "# Plot 1: Ablation Study (Vanilla vs. Enhanced DQN)\n",
    "ablation_df = eval_df[eval_df['agent'].isin(['dqn_vanilla', 'dqn_enhanced'])]\n",
    "plot_learning_curves(ablation_df, 'Ablation Study: Vanilla DQN vs. Enhanced DQN', x='step_in_millions')\n",
    "\n",
    "# Plot 2: Main Comparison (Enhanced DQN vs. PPO)\n",
    "main_comparison_df = eval_df[eval_df['agent'].isin(['dqn_enhanced', 'ppo'])]\n",
    "plot_learning_curves(main_comparison_df, 'Main Comparison: Enhanced DQN vs. PPO', x='step_in_millions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantitative Analysis\n",
    "\n",
    "Here, we can compute the specific metrics mentioned in the paper, such as 'Frames to +15 Score' and 'Final Score'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SCORE = 15\n",
    "FINAL_EVALS = 5\n",
    "\n",
    "summary = []\n",
    "\n",
    "for agent in AGENTS:\n",
    "    agent_df = eval_df[eval_df['agent'] == agent]\n",
    "    \n",
    "    # Frames to Target Score\n",
    "    frames_to_target = agent_df[agent_df['eval/mean_return'] >= TARGET_SCORE]['step'].min()\n",
    "    \n",
    "    # Final Score (average over last N evaluations per seed, then average seeds)\n",
    "    final_scores_per_seed = []\n",
    "    for seed in SEEDS:\n",
    "        seed_df = agent_df[agent_df['seed'] == seed]\n",
    "        if not seed_df.empty:\n",
    "            last_n_scores = seed_df.nlargest(FINAL_EVALS, 'step')['eval/mean_return']\n",
    "            final_scores_per_seed.append(last_n_scores.mean())\n",
    "    \n",
    "    final_score_mean = np.mean(final_scores_per_seed) if final_scores_per_seed else np.nan\n",
    "    final_score_std = np.std(final_scores_per_seed) if final_scores_per_seed else np.nan\n",
    "\n",
    "    summary.append({\n",
    "        'Agent': agent,\n",
    "        'Frames to +15 Score': frames_to_target,\n",
    "        'Final Score (Mean)': final_score_mean,\n",
    "        'Final Score (Std)': final_score_std\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}